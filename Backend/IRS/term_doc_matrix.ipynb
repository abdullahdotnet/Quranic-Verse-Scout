{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting with database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import db_credentials as creds\n",
    "mydb = mysql.connector.connect(\n",
    "    host=creds.host,\n",
    "    user=creds.user,\n",
    "    password=creds.password,\n",
    "    database=creds.database,\n",
    "    port = creds.port\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "mycursor.execute(\"SHOW TABLES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ayah_edition',)\n",
      "('ayahs',)\n",
      "('unique_eng_words',)\n"
     ]
    }
   ],
   "source": [
    "for x in mycursor:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6236, 5480)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create np array of size 6236x5480\n",
    "import numpy as np\n",
    "term_matrix = np.zeros((6236, 5480))\n",
    "term_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"SELECT * FROM ayah_edition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the name of Allah, most benevolent, ever-merciful.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to numpy array\n",
    "ayahs_records = np.array(mycursor.fetchall())\n",
    "ayahs_records[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting just ayah strings from records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['In the name of Allah, most benevolent, ever-merciful.',\n",
       "       'ALL PRAISE BE to Allah, Lord of all the worlds,',\n",
       "       'Most beneficent, ever-merciful,', ...,\n",
       "       'From the evil of him who breathes temptations into the minds of men,',\n",
       "       'Who suggests evil thoughts to the hearts of men --',\n",
       "       'From among the jinns and men.'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayahs = ayahs_records[:,3]\n",
    "ayahs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing symbols from ayah strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the name of allah most benevolent ever merciful'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in each record using regex extract only words without comma, dot, quotations marks and apostrophe and lower case them using numpy\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'-', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# apply the function to all the strings inside numpy array\n",
    "vfunc = np.vectorize(clean_text)\n",
    "cleaned_ayahs = vfunc(ayahs)\n",
    "cleaned_ayahs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting separate words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['in', 'the', 'name', 'of', 'allah', 'most', 'benevolent', 'ever', 'merciful']),\n",
       "       list(['all', 'praise', 'be', 'to', 'allah', 'lord', 'of', 'all', 'the', 'worlds']),\n",
       "       list(['most', 'beneficent', 'ever', 'merciful']), ...,\n",
       "       list(['from', 'the', 'evil', 'of', 'him', 'who', 'breathes', 'temptations', 'into', 'the', 'minds', 'of', 'men']),\n",
       "       list(['who', 'suggests', 'evil', 'thoughts', 'to', 'the', 'hearts', 'of', 'men']),\n",
       "       list(['from', 'among', 'the', 'jinns', 'and', 'men'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_array = np.char.split(cleaned_ayahs.astype(str))\n",
    "words_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting unique words from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"SELECT * FROM unique_eng_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', 'a'],\n",
       "       ['2', 'aaron'],\n",
       "       ['3', 'abandon'],\n",
       "       ...,\n",
       "       ['5478', 'zakat'],\n",
       "       ['5479', 'zaqqum'],\n",
       "       ['5480', 'zodiac']], dtype='<U15')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words_arr = np.array(mycursor.fetchall())\n",
    "unique_words_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling term document matrix\n",
    "Remember that inside the database, the indexing is starting from 1 but in the code, it is 0. Lets say we want to see the 'the' word inside the unique words inside the database. Its id is 4874 but here in the code, its index is 4873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, ayah in enumerate(words_array):\n",
    "    for word in ayah:\n",
    "        if word in unique_words_arr[:,1]:\n",
    "            term_matrix[idx,np.where(unique_words_arr[:,1] == word)[0]] = 1\n",
    "        \n",
    "term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_matrix[0][4873]    # finding 'the' in the first ayah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuranEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
