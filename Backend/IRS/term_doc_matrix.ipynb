{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting with database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import db_credentials as creds\n",
    "mydb = mysql.connector.connect(\n",
    "    host=creds.host,\n",
    "    user=creds.user,\n",
    "    password=creds.password,\n",
    "    database=creds.database,\n",
    "    port = creds.port\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "mycursor.execute(\"SHOW TABLES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ayah_edition',)\n",
      "('ayahs',)\n",
      "('unique_eng_words',)\n"
     ]
    }
   ],
   "source": [
    "for x in mycursor:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6236, 5480)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create np array of size 6236x5480\n",
    "import numpy as np\n",
    "term_matrix = np.zeros((6236, 5480))\n",
    "term_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"SELECT * FROM ayah_edition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the name of Allah, most benevolent, ever-merciful.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to numpy array\n",
    "ayahs_records = np.array(mycursor.fetchall())\n",
    "ayahs_records[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting just ayah strings from records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['In the name of Allah, most benevolent, ever-merciful.',\n",
       "       'ALL PRAISE BE to Allah, Lord of all the worlds,',\n",
       "       'Most beneficent, ever-merciful,', ...,\n",
       "       'From the evil of him who breathes temptations into the minds of men,',\n",
       "       'Who suggests evil thoughts to the hearts of men --',\n",
       "       'From among the jinns and men.'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayahs = ayahs_records[:,3]\n",
    "ayahs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store ayahs in pickle file\n",
    "import pickle\n",
    "with open(\"ayahs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ayahs, f)\n",
    "\n",
    "# load ayahs from pickle file\n",
    "with open(\"ayahs.pkl\", \"rb\") as f:\n",
    "    ayahs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing symbols from ayah strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the name of allah most benevolent ever merciful'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in each record using regex extract only words without comma, dot, quotations marks and apostrophe and lower case them using numpy\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    # also remove semicolon and colon\n",
    "    text = re.sub(r'-', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# apply the function to all the strings inside numpy array\n",
    "vfunc = np.vectorize(clean_text)\n",
    "cleaned_ayahs = vfunc(ayahs)\n",
    "cleaned_ayahs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting separate words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['in', 'the', 'name', 'of', 'allah', 'most', 'benevolent', 'ever', 'merciful']),\n",
       "       list(['all', 'praise', 'be', 'to', 'allah', 'lord', 'of', 'all', 'the', 'worlds']),\n",
       "       list(['most', 'beneficent', 'ever', 'merciful']), ...,\n",
       "       list(['from', 'the', 'evil', 'of', 'him', 'who', 'breathes', 'temptations', 'into', 'the', 'minds', 'of', 'men']),\n",
       "       list(['who', 'suggests', 'evil', 'thoughts', 'to', 'the', 'hearts', 'of', 'men']),\n",
       "       list(['from', 'among', 'the', 'jinns', 'and', 'men'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_array = np.char.split(cleaned_ayahs.astype(str))\n",
    "words_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting unique words from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"SELECT * FROM unique_eng_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', 'a'],\n",
       "       ['2', 'aaron'],\n",
       "       ['3', 'abandon'],\n",
       "       ...,\n",
       "       ['5478', 'zakat'],\n",
       "       ['5479', 'zaqqum'],\n",
       "       ['5480', 'zodiac']], dtype='<U15')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words_arr = np.array(mycursor.fetchall())\n",
    "unique_words_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing unique_words arr in pickle file\n",
    "with open('unique_words.pkl', 'wb') as f:\n",
    "    pickle.dump(unique_words_arr, f)\n",
    "\n",
    "# loading unique_words arr from pickle file\n",
    "with open('unique_words.pkl', 'rb') as f:\n",
    "    unique_words_arr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling term document matrix\n",
    "Remember that inside the database, the indexing is starting from 1 but in the code, it is 0. Lets say we want to see the 'the' word inside the unique words inside the database. Its id is 4874 but here in the code, its index is 4873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, ayah in enumerate(words_array):\n",
    "    for word in ayah:\n",
    "        if word in unique_words_arr[:,1]:\n",
    "            term_matrix[idx,np.where(unique_words_arr[:,1] == word)[0]] = 1\n",
    "        \n",
    "term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_matrix[0][4873]    # finding 'the' in the first ayah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the term document matrix in pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_chunks = 20\n",
    "\n",
    "chunks = np.array_split(term_matrix, number_of_chunks)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    with open(f'term_matrix/term_matrix_part_{i}.pkl', 'wb') as f:\n",
    "        pickle.dump(chunk, f)\n",
    "\n",
    "# loading matrix back\n",
    "term_matrix = []\n",
    "for i in range(number_of_chunks):\n",
    "    with open(f'term_matrix/term_matrix_part_{i}.pkl', 'rb') as f:\n",
    "        term_matrix.append(pickle.load(f))\n",
    "\n",
    "# Concatenate all chunks back into one array\n",
    "term_matrix = np.concatenate(term_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load term matrix from pickle file\n",
    "# with open('term_matrix.pickle', 'rb') as f:\n",
    "#     term_matrix = pickle.load(f)\n",
    "# term_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jannah', 'is', 'for', 'those', 'who', 'believe', 'in', 'allah']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = input(\"Your Question: \")\n",
    "# query = \"a the most gracious and the most merciful\"\n",
    "query = \"jannah is for those who believe in allah\"\n",
    "query = clean_text(query)\n",
    "query_words = query.split()\n",
    "query_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling the query vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column Vector\n",
    "query_vector = np.zeros((5480,1))\n",
    "for word in query_words:\n",
    "    if word in unique_words_arr[:,1]:\n",
    "        query_vector[np.where(unique_words_arr[:,1] == word)[0]] = 1\n",
    "\n",
    "query_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplying the query vector with the term document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.dot(term_matrix, query_vector)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the top 10 ayahs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 224],\n",
       "       [5095],\n",
       "       [ 887],\n",
       "       [1367],\n",
       "       [1706],\n",
       "       [3383],\n",
       "       [2852],\n",
       "       [1099],\n",
       "       [1878],\n",
       "       [ 223]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ayahs = np.argsort(result, axis=0)[::-1][:10]\n",
    "top_ayahs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the ayahs from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[224] Surely those who believe, and those who leave their homes and fight in the way of God, may hope for His benevolence, for God is forgiving and kind.\n",
      "[5095] Hasten for the forgiveness of your Lord and Paradise whose expanse is as wide as that of the heavens and the earth, which has been prepared for those who believe in God and His apostles. This is the bounty of God which He bestows on whosoever He please; and the bounty of God is infinite.\n",
      "[887] It is He who sends down water from the skies, and brings out of it everything that grows, the green foliage, the grain lying close, the date palm trees with clusters of dates, and the gardens of grapes, and of olives and pomegranates, so similar yet so unlike. Look at the fruits, how they appear on the trees, and they ripen. In all these are signs for those who believe.\n",
      "[1367] To Him will you all return: God's promise is true. It is He who originates creation, then will revert it, so that He may reward those who believe and do good things in all justice. But those who deny the truth will receive boiling water to drink and grievous punishment, for they disbelieved.\n",
      "[1706] Verily in their accounts is a lesson for men of wisdom. This is not a fictitious tale, but a verification of earlier Books, and a clear exposition of everything, and a guidance and grace for those who believe.\n",
      "[3383] God has created the heavens and the earth with reason. Surely in this is a sign for those who believe.\n",
      "[2852] There is no harm in your eating together or separately. But when you enter the houses, salute the inmates with a greeting in the name of God, invoking blessings and good health. That is how God explains things to you clearly so that you may understand. They alone are true believers who believe in God and His Apostle, and when they are with him on a matter of common concern, do not depart without obtaining his leave. Surely those who ask leave of you are the ones who believe in God and His Apostle. Therefore when they ask leave of you for personal business give leave to those you please, and seek God's forgiveness for them. Surely God is forgiving and kind.\n",
      "[1099] I will turn those away from My signs who behave unjustly with arrogance in the land so that even though they see all the signs they will not believe in them; and if they see the path of rectitude, will not take it to be a way; and if they see the way of error take it to be the (right) path. This is so for they have called Our messages lies, and have been heedless of them.\"\n",
      "[1878] Indeed there is a portent in this for those who believe.\n",
      "[223] They ask you of war in the holy month. Tell them: \"To fight in that month is a great sin. But a greater sin in the eyes of God is to hinder people from the way of God, and not to believe in Him, and to bar access to the Holy Mosque and turn people out of its precincts; and oppression is worse than killing. They will always seek war against you till they turn you away from your faith, if they can. But those of you who turn back on their faith and die disbelieving will have wasted their deeds in this world and the next. They are inmates of Hell, and shall there abide for ever.\n"
     ]
    }
   ],
   "source": [
    "for idx in top_ayahs:\n",
    "    print(idx, ayahs[idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  1,\n",
       "  '\\ufeffبِسْمِ ٱللَّهِ ٱلرَّحْمَٰنِ ٱلرَّحِيمِ',\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  datetime.datetime(2018, 6, 7, 8, 6, 54),\n",
       "  datetime.datetime(2018, 6, 7, 8, 6, 54))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycursor.execute(f\"SELECT * FROM ayahs WHERE id = {1}\")\n",
    "ayat = mycursor.fetchall()\n",
    "ayat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '\\ufeffبِسْمِ ٱللَّهِ ٱلرَّحْمَٰنِ ٱلرَّحِيمِ',\n",
       " 'verse_id': 1,\n",
       " 'surah_id': 1,\n",
       " 'ayat_number': '1:1'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ayat_obj = {\"text\":ayat[0][2], \"verse_id\":ayat[0][3], 'surah_id':ayat[0][5], \"ayat_number\":f\"{ayat[0][5]}:{ayat[0][3]}\"}\n",
    "ayat_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuranEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
